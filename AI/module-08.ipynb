{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "1. Change the name of this file to be your JHED id as in `jsmith299.ipynb`. Because sure you use your JHED ID (it's made out of your name and not your student id which is just letters and numbers).\n",
    "2. Make sure the notebook you submit is cleanly and fully executed. I do not grade unexecuted notebooks.\n",
    "3. Submit your notebook back in Blackboard where you downloaded this file.\n",
    "\n",
    "*Provide the output **exactly** as requested*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "For this assignment you will be implementing and evaluating a Decision Tree using the ID3 Algorithm (**no** pruning or normalized information gain). Use the provided pseudocode. The data is located at (copy link):\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "**Just in case** the UCI repository is down, which happens from time to time, I have included the data and name files on Blackboard.\n",
    "\n",
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <strong>Important</strong>\n",
    "    <p>\n",
    "        No Pandas. The only acceptable libraries in this class are those contained in the `environment.yml`. No OOP, either. You can used Dicts, NamedTuples, etc. as your abstract data type (ADT) for the the tree and nodes.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "One of the things we did not talk about in the lectures was how to deal with missing values. There are two aspects of the problem here. What do we do with missing values in the training data? What do we do with missing values when doing classifcation?\n",
    "\n",
    "For the first problem, C4.5 handled missing values in an interesting way. Suppose we have identifed some attribute *B* with values {b1, b2, b3} as the best current attribute. Furthermore, assume there are 5 observations with B=?, that is, we don't know the attribute value. In C4.5, those 5 observations would be added to *all* of the subsets created by B=b1, B=b2, B=b3 with decreased weights. Note that the observations with missing values are not part of the information gain calculation.\n",
    "\n",
    "This doesn't quite help us if we have missing values when we use the model. What happens if we have missing values during classification? One approach is to prepare for this advance. When you train the tree, you need to add an implicit attribute value \"?\" at every split. For example, if the attribute was \"size\" then the domain would be [\"small\", \"medium\", \"large\", \"?\"]. The \"?\" value gets all the data (because ? is now a wildcard). However, there is an issue with this approach. \"?\" becomes the worst possible attribut value because it has no classification value. What to do? There are several options:\n",
    "\n",
    "1. Never recurse on \"?\" if you do not also recurse on at least one *real* attribute value.\n",
    "2. Limit the depth of the tree.\n",
    "\n",
    "There are good reasons, in general, to limit the depth of a decision tree because they tend to overfit.\n",
    "Otherwise, the algorithm *will* exhaust all the attributes trying to fulfill one of the base cases.\n",
    "\n",
    "You must implement the following functions:\n",
    "\n",
    "`train` takes training_data and returns the Decision Tree as a data structure. There are many options including namedtuples and just plain old nested dictionaries. **No OOP**.\n",
    "\n",
    "```\n",
    "def train(training_data, depth_limit=None):\n",
    "   # returns the Decision Tree.\n",
    "```\n",
    "\n",
    "The `depth_limit` value defaults to None. (What technique would we use to determine the best parameter value for `depth_limit` hint: Module 3!)\n",
    "\n",
    "`classify` takes a tree produced from the function above and applies it to labeled data (like the test set) or unlabeled data (like some new data).\n",
    "\n",
    "```\n",
    "def classify(tree, observations, labeled=True):\n",
    "    # returns a list of classifications\n",
    "```\n",
    "\n",
    "`evaluate` takes a data set with labels (like the training set or test set) and the classification result and calculates the classification error rate:\n",
    "\n",
    "$$error\\_rate=\\frac{errors}{n}$$\n",
    "\n",
    "Do not use anything else as evaluation metric or the submission will be deemed incomplete, ie, an \"F\". (Hint: accuracy rate is not the error rate!).\n",
    "\n",
    "`cross_validate` takes the data and uses 10 fold cross validation (from Module 3!) to `train`, `classify`, and `evaluate`. **Remember to shuffle your data before you create your folds**. I leave the exact signature of `cross_validate` to you but you should write it so that you can use it with *any* `classify` function of the same form (using higher order functions and partial application).\n",
    "\n",
    "Following Module 3's discussion, `cross_validate` should print out the fold number and the evaluation metric (error rate) for each fold and then the average value (and the variance). What you are looking for here is a consistent evaluation metric cross the folds. You should print the error rates in terms of percents (ie, multiply the error rate by 100 and add \"%\" to the end).\n",
    "\n",
    "```\n",
    "def pretty_print_tree(tree):\n",
    "    # pretty prints the tree\n",
    "```\n",
    "\n",
    "This should be a text representation of a decision tree trained on the entire data set (no train/test).\n",
    "\n",
    "To summarize...\n",
    "\n",
    "Apply the Decision Tree algorithm to the Mushroom data set using 10 fold cross validation and the error rate as the evaluation metric. When you are done, apply the Decision Tree algorithm to the entire data set and print out the resulting tree.\n",
    "\n",
    "**Note** Because this assignment has a natural recursive implementation, you should consider using `deepcopy` at the appropriate places.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import List, Dict, Tuple, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> List[List]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = [value for value in line.rstrip().split(\",\")]\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse_data(\"agaricus-lepiota.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 1083,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8124"
      ]
     },
     "execution_count": 1084,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(xs: List, n: int) -> List[List[List]]:\n",
    "    k, m = divmod(len(xs), n)\n",
    "    # be careful of generators...\n",
    "    return list(xs[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = create_folds(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1087,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(folds: List[List[List]], index: int) -> Tuple[List[List], List[List]]:\n",
    "    training = []\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = training + fold\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = create_train_test(folds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7311"
      ]
     },
     "execution_count": 1090,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "813"
      ]
     },
     "execution_count": 1091,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"count_total\"></a> count_total\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**data** the training set\n",
    "\n",
    "**picked_attributes** The relevant attributes\n",
    "\n",
    "**picked_vals** The relevant values of those attributes\n",
    "\n",
    "**returns** Total, an int\n",
    "\n",
    "This function counts the amount of rows in **data** whose attributes in **picked_attributes** are the values in **picked_vals**. This allows us to compare the entropy of the next potential attributes at any level in the tree in [build_entropy_dict](#build_entropy_dict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_total(data,picked_attributes=[],picked_vals=[]):\n",
    "    total = 0\n",
    "    for row in range(len(data)):\n",
    "        to_continue = False\n",
    "        for i in range(len(picked_attributes)):\n",
    "            if data[row][picked_attributes[i]] != picked_vals[i]:\n",
    "                to_continue = True\n",
    "                break\n",
    "        if to_continue:\n",
    "            continue\n",
    "        total += 1\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [\n",
    "    ['a','b','c'],\n",
    "    ['a','b','d'],\n",
    "    ['a','e','b']\n",
    "]\n",
    "picked_attributes=[1]\n",
    "picked_vals=['b']\n",
    "assert(count_total(data1,picked_attributes,picked_vals) == 2)\n",
    "picked_attributes=[2]\n",
    "assert(count_total(data1,picked_attributes,picked_vals) == 1)\n",
    "picked_attributes=[1,2]\n",
    "picked_vals=['b','d']\n",
    "assert(count_total(data1,picked_attributes,picked_vals) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"calculate_entropy\"></a> calculate_entropy\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**x** a float in [0,1] or a list of such floats\n",
    "\n",
    "\n",
    "**returns** entropy, a float in [0,1)\n",
    "\n",
    "This function calculates the entropy of a list.  If **x** is a float, it calculates the entropy of **x** and its complement. This allows us to calculate the entropy of the next potential attributes at any level in the tree in [build_entropy_dict](#build_entropy_dict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(x):\n",
    "    entropy = 0\n",
    "    if type(x) == list:\n",
    "        for i in x:\n",
    "            try:\n",
    "                entropy -= i*math.log2(i)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    else:\n",
    "        try:\n",
    "            entropy = -x*math.log2(x)-(1-x)*math.log2(1-x)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(calculate_entropy(1/2)==1)\n",
    "assert(calculate_entropy(1)==0)\n",
    "assert(calculate_entropy(0)==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"build_attribute_dict\"></a> build_attribute_dict\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**data** the training set\n",
    "\n",
    "**picked_attributes** The relevant attributes\n",
    "\n",
    "**picked_vals** The relevant values of those attributes\n",
    "\n",
    "**returns** attribute_dict, a dict with key:value pairs, attribute:{'p':`count of p`, 'e': `count of e`}\n",
    "\n",
    "This function maps each attribute to the counts of each classification for the rows in **data** whose attributes in **picked_attributes** are the values in **picked_vals**. This allows us to compare the entropy of the next potential attributes at any level in the tree in [build_entropy_dict](#build_entropy_dict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_attribute_dict(data,picked_attributes=[],picked_vals=[]):\n",
    "    total = count_total(data,picked_attributes,picked_vals)\n",
    "    \n",
    "    attribute_dict = {i:{} for i in range(1,len(data[0])) if i not in picked_attributes}\n",
    "    for i in range(1,len(data[0])):\n",
    "        if i in picked_attributes:\n",
    "            continue\n",
    "        for row in range(len(data)):\n",
    "            to_continue = False\n",
    "            for j in range(len(picked_attributes)):\n",
    "                if data[row][picked_attributes[j]] != picked_vals[j]:\n",
    "                    to_continue = True\n",
    "                    break\n",
    "            if to_continue:\n",
    "                continue\n",
    "\n",
    "            if data[row][i] not in attribute_dict[i].keys():\n",
    "                attribute_dict[i][data[row][i]] = {'p':0,'e':0}\n",
    "\n",
    "            if data[row][0] == 'p':\n",
    "                attribute_dict[i][data[row][i]]['p']+=1\n",
    "            else:\n",
    "                attribute_dict[i][data[row][i]]['e']+=1\n",
    "                    \n",
    "    return attribute_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: {'a2': {'p': 1, 'e': 1}}}\n"
     ]
    }
   ],
   "source": [
    "test_data1 =[['p','a1','a2'],\n",
    "             ['p','b1','b2'],\n",
    "             ['e','c1','a2'],\n",
    "             ['p','c1','a2']\n",
    "             ]\n",
    "test_att_dict = build_attribute_dict(test_data1)\n",
    "assert(test_att_dict == {1:{'a1':{'p':1,'e':0},'b1':{'p':1,'e':0},\n",
    "                            'c1':{'p':1,'e':1}},2:{'a2':{'p':2,'e':1},'b2':{'p':1,'e':0}}})\n",
    "\n",
    "picked_attributes=[1]\n",
    "picked_vals=['c1']\n",
    "\n",
    "test_att_dict2 = build_attribute_dict(test_data1,picked_attributes,picked_vals)\n",
    "print(test_att_dict2)\n",
    "assert(test_att_dict2 == {2:{'a2':{'p':1,'e':1}}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"build_entropy_dict\"></a> build_entropy_dict\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**attribute_dict** the map built in [build_attribute_dict](#build_attribute_dict)\n",
    "\n",
    "**total** The total amount of remaining rows in the subtree\n",
    "\n",
    "**returns** entropy_dict, a dict with key:value pairs, attribute:entropy\n",
    "\n",
    "This function maps each attribute to its entropy at each level in the subtree. It can then be used to [pick the best attribute](#pick_best_attribute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_entropy_dict(attribute_dict,total):\n",
    "    entropy_dict = {}\n",
    "    for k in attribute_dict.keys():\n",
    "        entropy = 0\n",
    "        for c in attribute_dict[k].keys():\n",
    "            t = attribute_dict[k][c]['p']+attribute_dict[k][c]['e']\n",
    "            e = calculate_entropy(attribute_dict[k][c]['p']/t)\n",
    "            entropy += e*t/total\n",
    "        entropy_dict[k] = entropy\n",
    "    return entropy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.5, 2: 0.6887218755408672}\n"
     ]
    }
   ],
   "source": [
    "ed = build_entropy_dict(test_att_dict,4)\n",
    "print(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"build_attribute_dict\"></a> build_attribute_dict\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**data** the training set\n",
    "\n",
    "**picked_attributes** The relevant attributes\n",
    "\n",
    "**picked_vals** The relevant values of those attributes\n",
    "\n",
    "**returns** best_attribute, the int of the column in data containing the next best attribute to decide on.\n",
    "\n",
    "This picks the next best attribute (the one with the lowest entropy) in **data** whose attributes in **picked_attributes** are the values in **picked_vals**. This allows us to pick the next best attribute to build the subtree out of in [id3](#id3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_attribute(data,picked_attributes=[],picked_vals=[]):\n",
    "    best_attribute = None\n",
    "    best_value = 2\n",
    "    attribute_dict = build_attribute_dict(data,picked_attributes,picked_vals)\n",
    "\n",
    "    total = count_total(data,picked_attributes,picked_vals)\n",
    "    entropy_dict = build_entropy_dict(attribute_dict,total)\n",
    "    for k in entropy_dict.keys():\n",
    "        if entropy_dict[k] < best_value:\n",
    "            best_attribute = k\n",
    "            best_value = entropy_dict[k]\n",
    "                \n",
    "    return best_attribute\n",
    "                \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(pick_best_attribute(test_data1) == 1)\n",
    "picked_attributes=[1]\n",
    "picked_vals=['c1']\n",
    "assert(pick_best_attribute(test_data1,picked_attributes,picked_vals) == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"check_homogeneous\"></a> check_homogeneous\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**data** the training set\n",
    "\n",
    "**picked_attributes** The relevant attributes\n",
    "\n",
    "**picked_vals** The relevant values of those attributes\n",
    "\n",
    "**returns** A tuple of form (boolean,string) where the boolean determines if the remaining data for the subtree is homogeneous, and the string is the majority classification, regardless of if the subtree is homogeneous\n",
    "\n",
    "This checks to see if the classifications in **data** whose attributes in **picked_attributes** are the values in **picked_vals**. This allows us to end recursion in a subtree in [id3](#id3).  This function is also used when the depth limit is reached or there are no more attributes remaining.  So, the majority classification will be returned to serve the pseudocode.  I disagree with this approach, because we are trying to classify mushrooms as poisonous or edible, and any uncertainty should default to poisonous.  By switching the `'e'` to a `'p'` in the final return statement, we can see the effects of this approach.  With this particular data set, shallow trees will have much greater error rates, but at a depth level of at least 4, the error rate drops to 0, regardless of the approach.  This is simply due to the fact that a decision tree can be made out of finite data, and is not an endorsement of the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_homogeneous(data,picked_attributes,picked_vals):\n",
    "    p_count = 0\n",
    "    s_count = 0\n",
    "    homogeneous = True\n",
    "    is_first_row = True\n",
    "    first_row = []\n",
    "    for row in data:\n",
    "        to_continue = False\n",
    "        for i in range(len(picked_attributes)):\n",
    "            if row[picked_attributes[i]]!=picked_vals[i]:\n",
    "                to_continue = True\n",
    "        if to_continue:\n",
    "            continue\n",
    "        if is_first_row:\n",
    "            first_row = deepcopy(row)\n",
    "            for v in picked_vals:\n",
    "                first_row.remove(v)\n",
    "            is_first_row = False\n",
    "            first_row = first_row[1:]\n",
    "        else:\n",
    "            next_row = deepcopy(row)\n",
    "            for v in picked_vals:\n",
    "                next_row.remove(v)\n",
    "            next_row = next_row[1:]\n",
    "            if next_row != first_row:\n",
    "                homogeneous = False\n",
    "        if row[0] == 'p':\n",
    "            p_count+=1\n",
    "        else:\n",
    "            s_count+=1\n",
    "    if p_count ==0:\n",
    "        return True, 'e'\n",
    "    if s_count ==0:\n",
    "        return True, 'p'\n",
    "    if p_count >= s_count:\n",
    "        return homogeneous, 'p'\n",
    "    return homogeneous, 'e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [\n",
    "    ['p','b','c'],\n",
    "    ['p','b','d'],\n",
    "    ['p','e','b']\n",
    "]\n",
    "picked_attributes=[]\n",
    "picked_vals=[]\n",
    "\n",
    "assert(check_homogeneous(data1,picked_attributes,picked_vals) == (True,'p'))\n",
    "data1 = [\n",
    "    ['p','b','c'],\n",
    "    ['p','b','b'],\n",
    "    ['s','e','b']\n",
    "]\n",
    "\n",
    "assert(check_homogeneous(data1,picked_attributes,picked_vals) == (False,'p'))\n",
    "picked_attributes=[1]\n",
    "picked_vals=['b']\n",
    "assert(check_homogeneous(data1,picked_attributes,picked_vals) == (True,'p'))\n",
    "picked_attributes=[2]\n",
    "assert(check_homogeneous(data1,picked_attributes,picked_vals) == (False,'p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"id3\"></a> id3\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**data** the training set\n",
    "\n",
    "**picked_attributes** The relevant attributes\n",
    "\n",
    "**picked_vals** The relevant values of those attributes\n",
    "\n",
    "**depth** The remaining allowable recursive depth of the tree\n",
    "\n",
    "**returns** subtree, a dict with key:value pairs `(attribute,value):x`, where `x` is a subtree of that subtree, or `'p'` or `'e'`.\n",
    "\n",
    "This recursively builds the decision tree that will be used to [classify](#classify) a mushroom as poisonous (p) or edible (e).  All defaults or missing values map to `'p'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data, picked_attributes=[], picked_vals=[],depth = float('inf')):\n",
    "    subtree={}\n",
    "    if len(data) == 0:\n",
    "        return 'p'\n",
    "    homogeneous = check_homogeneous(data, picked_attributes, picked_vals)\n",
    "    \n",
    "    if homogeneous[0] or depth == 0:\n",
    "        return homogeneous[1]\n",
    "        \n",
    "    if len(data[0]) == len(picked_attributes) + 1:\n",
    "        return homogeneous[1]\n",
    "\n",
    "    best_attribute = pick_best_attribute(data, picked_attributes, picked_vals)\n",
    "    for row in data:\n",
    "        to_continue = False\n",
    "        for i in range(len(picked_attributes)):\n",
    "            if row[picked_attributes[i]] != picked_vals[i]:\n",
    "                to_continue = True\n",
    "                break\n",
    "        if to_continue:\n",
    "            continue\n",
    "        if not (best_attribute,row[best_attribute]) in subtree.keys():\n",
    "            p = deepcopy(picked_attributes)\n",
    "            v = deepcopy(picked_vals)\n",
    "            p.append(best_attribute)\n",
    "            v.append(row[best_attribute])\n",
    "            if row[best_attribute] == '?':\n",
    "                subtree[(best_attribute,row[best_attribute])] = 'p'\n",
    "            else:\n",
    "                subtree[(best_attribute,row[best_attribute])] = id3(data, p, v,depth-1)\n",
    "    return subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 'a1'): 'p', (1, 'b1'): 'p', (1, 'c1'): 'p'}\n",
      "{(2, 'a2'): {(1, 'a1'): {(3, 'a3'): 'p', (3, 'b3'): 'e'}, (1, 'c1'): 'e'}, (2, 'b2'): 'p', (2, 'c2'): 'p'}\n"
     ]
    }
   ],
   "source": [
    "print(id3(test_data1))\n",
    "test_data2 =[['p','a1','a2','a3'],\n",
    "             ['p','b1','b2','a3'],\n",
    "             ['e','c1','a2','b3'],\n",
    "             ['p','c1','a2','a3'],\n",
    "             ['e','d1','c2','b3']\n",
    "             ]\n",
    "assert(id3(test_data2) == {(3,'a3'):'p',(3,'b3'):'e'})\n",
    "\n",
    "test_data3 =[['p','a1','a2','a3','a4'],\n",
    "             ['p','c1','b2','a3','d4'],\n",
    "             ['e','a1','a2','b3','a4'],\n",
    "             ['e','c1','a2','a3','d4'],\n",
    "             ['p','c1','c2','b3','e4'],\n",
    "             ['e','c1','c2','b3','e4']\n",
    "             ]\n",
    "assert(id3(test_data3,depth=2)!=id3(test_data3,depth=3))\n",
    "assert(id3(test_data3,depth=2)!=id3(test_data3))\n",
    "print(id3(test_data3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"tree_fixer\"></a> tree_fixer\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**tree** A decision tree, with `type(tree) == dict` evaluates to `True`\n",
    "\n",
    "**returns** A fixed version of **tree**\n",
    "\n",
    "This helper function fixes an issue with homogeneity that isn't addressed in [id3](#id3).  Specifically, it turns subtrees of the form `{(1,'a'):{(2,'b'):'p',(2,'c'):'p'}, (1,'d'):'e'}` to the form `{(1,'a'):'p',(1,'d'):'e'}`, since [check_homogeneous](#check_homogeneous) doesn't account for homogeneity of remaining values.  This issue only seemed to arise at the first depth of the tree, so it is likely that **depth_limit** in [train](#train) will produce trees that are 1 level shallower than intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_fixer(tree):\n",
    "    p_count = 0\n",
    "    s_count = 0\n",
    "    for k in tree.keys():\n",
    "        if type(tree[k]) == dict:\n",
    "            tree[k] = tree_fixer(tree[k])\n",
    "        if tree[k] == 'p':\n",
    "            p_count +=1\n",
    "        if tree[k] == 'e':\n",
    "            s_count +=1\n",
    "    for k in tree.keys():\n",
    "        if type(tree[k]) == dict:\n",
    "            return tree\n",
    "    if s_count == 0:\n",
    "        return 'p'\n",
    "    if p_count == 0:\n",
    "        return 'e'\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(tree_fixer(id3(test_data1))=='p')\n",
    "bad_tree1 = {'a': {'b': 'p','e':'p'}, 'c':{'d':'e','h':'e'}}\n",
    "assert(tree_fixer(bad_tree1)=={'a':'p','c':'e'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"pretty_print_tree\"></a> pretty_print_tree\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**tree** A decision tree, with `type(tree) == dict` evaluates to `True`\n",
    "\n",
    "**returns** `None`\n",
    "\n",
    "**prints** A string version of **tree**\n",
    "\n",
    "This function prints the decision tree in a way that I think is pretty.  Child trees are located below and to the right of their parent tree.  Siblings are located directly vertical from each other.  Leaves are located to the very left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_tree(tree):\n",
    "    tree_str = str(tree)\n",
    "    space = \" \"\n",
    "    c = 0\n",
    "    while c < len(tree_str):\n",
    "        if tree_str[c] == '{':\n",
    "            c+=1\n",
    "            continue\n",
    "        elif tree_str[c] ==':':\n",
    "            print()\n",
    "            space += \" \"*5\n",
    "        elif tree_str[c] =='}':\n",
    "            space = space[:len(space)-5]\n",
    "            print()\n",
    "        elif tree_str[c] =='(':\n",
    "            print(space,end = '') != ':'\n",
    "            while tree_str[c] != ':':\n",
    "                print(tree_str[c],end='')\n",
    "                c+=1\n",
    "            print(tree_str[c],end='')\n",
    "            print()\n",
    "            space += \" \"*5\n",
    "        elif tree_str[c] =='\\'':\n",
    "            print(tree_str[c],end='')\n",
    "            c+=1\n",
    "            print(tree_str[c],end='')\n",
    "            c+=1\n",
    "            print(tree_str[c],end='')\n",
    "            print()\n",
    "            \n",
    "        c+=1\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (1, 'b'):\n",
      "'p'\n",
      "      (1, 'e'):\n",
      "'e'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print_tree(tree_fixer(id3(data1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"train\"></a> train\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**training_data** A list of lists of data to train a tree on\n",
    "\n",
    "**depth_limit**  `None`, or the maximum depth of the tree \n",
    "\n",
    "**returns** A decision tree\n",
    "\n",
    "This function creates the tree from the training data.  [tree_fixer](#tree_fixer) may cause the recursion to be off by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data,depth_limit = None):\n",
    "    if depth_limit == None:\n",
    "        return tree_fixer(id3(training_data))\n",
    "    return tree_fixer(id3(training_data,depth = depth_limit))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"classify\"></a> classify\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**tree** A decision tree as a nested dict\n",
    "\n",
    "**observations**  a list of attribute values observed\n",
    "\n",
    "**labeled** Whether the observations are labeled with a classification.\n",
    "\n",
    "**returns** `'p'` or `'e'`, if the mushroom is poisonous or edible, based on the observations.\n",
    "\n",
    "This classifies observations based on a decision tree.  The labeled parameter helps determine if we are testing or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, observations, labeled=True):\n",
    "    observations_copy = deepcopy(observations)\n",
    "    if not labeled:\n",
    "        observations_copy = [''] + observations_copy\n",
    "    classification = tree\n",
    "    while type(classification) != str:\n",
    "        broken = False\n",
    "        for i in range(1, len(observations_copy)):\n",
    "            for o in classification.keys():\n",
    "                if o[0] != i:\n",
    "                    break\n",
    "                if o[1] == observations_copy[i]:\n",
    "                    classification = classification[o]\n",
    "                    broken = True\n",
    "                    break\n",
    "            if broken:\n",
    "                break\n",
    "        if not broken:\n",
    "            return 'p'\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n"
     ]
    }
   ],
   "source": [
    "tree_test1 = {'a':{'b':'c','d':{'e':'f'}},'g':'h'}\n",
    "observation1 = ['a','d','e']\n",
    "print(classify(tree_test1,observation1,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"evaluate\"></a> evaluate\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**tree** A decision tree as a nested dict\n",
    "\n",
    "**test**  A list of lists of test data\n",
    "\n",
    "**model** A higher order function, but actually just [classify](#classify)\n",
    "\n",
    "**returns** The error rate: amount of errors/total\n",
    "\n",
    "This determines the error rate of the tree on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tree,test,model):\n",
    "    total = len(test)\n",
    "    error = 0\n",
    "    for data_point in test:\n",
    "        prediction = model(tree,data_point)\n",
    "        actual = data_point[0]\n",
    "        if actual!=prediction:\n",
    "            error+=1\n",
    "    \n",
    "    rate = error/total\n",
    "    return rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"evaluate\"></a> evaluate\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**folds** A decision tree as a nested dict\n",
    "\n",
    "**depth_limit**  The maximum depth of the tree\n",
    "\n",
    "**labeled** Whether the data is labeled or not.  Used by [classify](#classify)\n",
    "\n",
    "**returns** The average error rate of 10 folds of cross validation\n",
    "\n",
    "**prints** Average error rate, variance\n",
    "\n",
    "This determines the average error rate and variance of the different trees over 10 folds of cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(folds,depth_limit=None,labeled=True):\n",
    "    print(\"tree evaluation with \"+ str(depth_limit)+ \" depth limit\")\n",
    "    total = 0\n",
    "    rates = []\n",
    "    variance = 0\n",
    "    for i in range(10):\n",
    "        training, test = create_train_test(folds, i)\n",
    "        tree = train(training,depth_limit)\n",
    "        error = evaluate(tree,test,classify)\n",
    "        print(\"fold \"+str(i)+ \" error rate: \" + str(100*error)+\"%\")\n",
    "        total += error\n",
    "        rates.append(error)\n",
    "      \n",
    "    mean = total/10\n",
    "    for r in rates:\n",
    "        variance += (r-mean)**2\n",
    "        \n",
    "    variance /=9\n",
    "        \n",
    "        \n",
    "\n",
    "    print(\"mean error rate: \" + str(100*mean)+\"%\")\n",
    "    print(\"variance: \" + str(100*variance) +\"%\")\n",
    "    return 100*total/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree evaluation with None depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 1115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = create_folds(data,10)\n",
    "cross_validate(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"depth_tuner\"></a> depth_tuner\n",
    "\n",
    "Formal Parameters:\n",
    "\n",
    "**upper_bound** The max bound to tune the max depth of the tree to\n",
    "\n",
    "**folds** The training data\n",
    "\n",
    "**returns** The depth with the least average error. Breaks ties by minimum max depth\n",
    "\n",
    "**prints** A summary of what is going on\n",
    "\n",
    "This tunes the depth hyperparameter to make the best tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation for trees of different depths\n",
      "depth = 1\n",
      "tree evaluation with 1 depth limit\n",
      "fold 0 error rate: 1.4760147601476015%\n",
      "fold 1 error rate: 0.984009840098401%\n",
      "fold 2 error rate: 1.3530135301353015%\n",
      "fold 3 error rate: 1.968019680196802%\n",
      "fold 4 error rate: 1.2315270935960592%\n",
      "fold 5 error rate: 1.600985221674877%\n",
      "fold 6 error rate: 0.9852216748768473%\n",
      "fold 7 error rate: 1.7241379310344827%\n",
      "fold 8 error rate: 1.2315270935960592%\n",
      "fold 9 error rate: 2.2167487684729066%\n",
      "mean error rate: 1.4771205593829337%\n",
      "variance: 0.001650611825984985%\n",
      "depth = 2\n",
      "tree evaluation with 2 depth limit\n",
      "fold 0 error rate: 0.4920049200492005%\n",
      "fold 1 error rate: 0.6150061500615006%\n",
      "fold 2 error rate: 0.12300123001230012%\n",
      "fold 3 error rate: 0.984009840098401%\n",
      "fold 4 error rate: 0.12315270935960591%\n",
      "fold 5 error rate: 0.7389162561576355%\n",
      "fold 6 error rate: 0.6157635467980296%\n",
      "fold 7 error rate: 0.6157635467980296%\n",
      "fold 8 error rate: 0.3694581280788177%\n",
      "fold 9 error rate: 1.2315270935960592%\n",
      "mean error rate: 0.5908603421009578%\n",
      "variance: 0.0012057758227959608%\n",
      "depth = 3\n",
      "tree evaluation with 3 depth limit\n",
      "fold 0 error rate: 0.24600246002460024%\n",
      "fold 1 error rate: 0.4920049200492005%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.6150061500615006%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.24630541871921183%\n",
      "fold 6 error rate: 0.3694581280788177%\n",
      "fold 7 error rate: 0.49261083743842365%\n",
      "fold 8 error rate: 0.12315270935960591%\n",
      "fold 9 error rate: 0.3694581280788177%\n",
      "mean error rate: 0.2953998751810178%\n",
      "variance: 0.0004441163964627625%\n",
      "depth = 4\n",
      "tree evaluation with 4 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 5\n",
      "tree evaluation with 5 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 6\n",
      "tree evaluation with 6 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 7\n",
      "tree evaluation with 7 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 8\n",
      "tree evaluation with 8 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 9\n",
      "tree evaluation with 9 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 10\n",
      "tree evaluation with 10 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 11\n",
      "tree evaluation with 11 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 12\n",
      "tree evaluation with 12 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 13\n",
      "tree evaluation with 13 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 14\n",
      "tree evaluation with 14 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 15\n",
      "tree evaluation with 15 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 16\n",
      "tree evaluation with 16 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 17\n",
      "tree evaluation with 17 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 18\n",
      "tree evaluation with 18 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 19\n",
      "tree evaluation with 19 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 20\n",
      "tree evaluation with 20 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 21\n",
      "tree evaluation with 21 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "depth = 22\n",
      "tree evaluation with 22 depth limit\n",
      "fold 0 error rate: 0.0%\n",
      "fold 1 error rate: 0.0%\n",
      "fold 2 error rate: 0.0%\n",
      "fold 3 error rate: 0.0%\n",
      "fold 4 error rate: 0.0%\n",
      "fold 5 error rate: 0.0%\n",
      "fold 6 error rate: 0.0%\n",
      "fold 7 error rate: 0.0%\n",
      "fold 8 error rate: 0.0%\n",
      "fold 9 error rate: 0.0%\n",
      "mean error rate: 0.0%\n",
      "variance: 0.0%\n",
      "best depth is 4 with error rate 0.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def depth_tuner(upper_bound,folds):\n",
    "    print(\"Classification evaluation for trees of different depths\")\n",
    "    best_depth = 0\n",
    "    smallest_error_rate = float('inf')\n",
    "\n",
    "    for j in range(1,upper_bound):\n",
    "        print(\"depth = \" + str(j))\n",
    "        k = cross_validate(folds,j)\n",
    "        if k < smallest_error_rate:\n",
    "            smallest_error_rate = k\n",
    "            best_depth = j\n",
    "            \n",
    "    print(\"best depth is \" + str(best_depth)+ \" with error rate \" + str(smallest_error_rate) +\"%\")\n",
    "    return best_depth\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "folds = create_folds(data,10)\n",
    "depth_tuner(23,folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (5, 'n'):\n",
      "      (20, 'k'):\n",
      "'e'\n",
      "           (20, 'n'):\n",
      "'e'\n",
      "                (20, 'w'):\n",
      "                     (22, 'g'):\n",
      "'e'\n",
      "                          (22, 'p'):\n",
      "'e'\n",
      "                               (22, 'l'):\n",
      "                                    (3, 'y'):\n",
      "'p'\n",
      "                                         (3, 'n'):\n",
      "'e'\n",
      "                                              (3, 'c'):\n",
      "'e'\n",
      "                                                   (3, 'w'):\n",
      "'p'\n",
      "\n",
      "                                                   (22, 'w'):\n",
      "'e'\n",
      "                                                        (22, 'd'):\n",
      "                                                             (8, 'n'):\n",
      "'p'\n",
      "                                                                  (8, 'b'):\n",
      "'e'\n",
      "\n",
      "\n",
      "                                                             (20, 'b'):\n",
      "'e'\n",
      "                                                                  (20, 'r'):\n",
      "'p'\n",
      "                                                                       (20, 'o'):\n",
      "'e'\n",
      "                                                                            (20, 'h'):\n",
      "'e'\n",
      "                                                                                 (20, 'y'):\n",
      "'e'\n",
      "\n",
      "                                                                                 (5, 'l'):\n",
      "'e'\n",
      "                                                                                      (5, 'f'):\n",
      "'p'\n",
      "                                                                                           (5, 's'):\n",
      "'p'\n",
      "                                                                                                (5, 'y'):\n",
      "'p'\n",
      "                                                                                                     (5, 'm'):\n",
      "'p'\n",
      "                                                                                                          (5, 'a'):\n",
      "'e'\n",
      "                                                                                                               (5, 'c'):\n",
      "'p'\n",
      "                                                                                                                    (5, 'p'):\n",
      "'p'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print_tree(tree_fixer(id3(data,depth=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Did you provide output exactly as requested?\n",
    "2. Did you re-execute the entire notebook? (\"Restart Kernel and Rull All Cells...\")\n",
    "3. If you did not complete the assignment or had difficulty please explain what gave you the most difficulty in the Markdown cell below.\n",
    "4. Did you change the name of the file to `jhed_id.ipynb`?\n",
    "\n",
    "Do not submit any other files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en605645)",
   "language": "python",
   "name": "en605645"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
